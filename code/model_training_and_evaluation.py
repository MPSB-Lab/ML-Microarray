# -*- coding: utf-8 -*-
"""model_training_and_evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hY-xCF50DeQOINPLFE8AcpatzyKtShDf
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    matthews_corrcoef, roc_auc_score, confusion_matrix
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler

from google.colab import drive
drive.mount('/content/drive')

expr_file = "/content/drive/MyDrive/GENE.xlsx" #your dataset
expr_df = pd.read_excel(expr_file,sheet_name="ANTISENSE")

gene_names = expr_df.iloc[:, 0].astype(str)
expr_data = expr_df.iloc[:, 1:]

# classify samples: controls have 'UNC' in name
control_cols = [col for col in expr_data.columns if 'UNC' in col]
infected_cols = [col for col in expr_data.columns if 'UNC' not in col]

X_all = expr_data[control_cols + infected_cols].T
X_all.columns = gene_names
y = np.array([0]*len(control_cols) + [1]*len(infected_cols))  # 0 = control, 1 = infected
X=X_all.values

models = {
    'Random Forest': RandomForestClassifier(n_estimators=10,random_state=42),
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'XGBoost' : XGBClassifier(n_estimators=100,max_depth=2,learning_rate=0.05,subsample=0.8,colsample_bytree=0.8,reg_alpha=0.1,reg_lambda=1,eval_metric='logloss',random_state=42)
}

# cross
loo = LeaveOneOut()
all_results = []

for model_name, model in models.items():
    y_true_all, y_pred_all, y_prob_all = [], [], []

    for train_idx, test_idx in loo.split(X, y):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)

        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_true_all.extend(y_test)
        y_pred_all.extend(y_pred)

        if hasattr(model, "predict_proba"):
            y_prob = model.predict_proba(X_test)[:, 1]
        else:
            y_prob = model.decision_function(X_test)
        y_prob_all.extend(y_prob)

    # compute metrics
    acc = accuracy_score(y_true_all, y_pred_all)
    prec = precision_score(y_true_all, y_pred_all, zero_division=0)
    rec = recall_score(y_true_all, y_pred_all)
    f1 = f1_score(y_true_all, y_pred_all)
    mcc = matthews_corrcoef(y_true_all, y_pred_all)
    try:
        auc = roc_auc_score(y_true_all, y_prob_all)
    except:
        auc = np.nan

    tn, fp, fn, tp = confusion_matrix(y_true_all, y_pred_all).ravel()
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0

    all_results.append({
        "Model": model_name,
        "Accuracy": round(acc, 3),
        "Precision": round(prec, 3),
        "Sensitivity": round(rec, 3),
        "Specificity": round(specificity, 3),
        "F1 Score": round(f1, 3),
        "MCC": round(mcc, 3),
        "AUC": round(auc, 3)
    })

    print(f"{model_name}: ACC={acc:.3f}, F1={f1:.3f}, AUC={auc:.3f}, MCC={mcc:.3f}")

results_df = pd.DataFrame(all_results)
path="/content/drive/MyDrive/SAME_ANTISENSE.csv" #change to your path
results_df.to_csv(path, index=False)
print(f"\n saved to {path}")
