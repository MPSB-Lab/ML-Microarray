# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QgIs5jz8F8y7tvobCMJGme-4J_KQwYB6
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    matthews_corrcoef, roc_auc_score, confusion_matrix
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.preprocessing import StandardScaler

from google.colab import drive
drive.mount('/content/drive')

expr_file = "/content/drive/MyDrive/Training_Dataset_2_Yash.xlsx"
expr_df = pd.read_excel(expr_file,sheet_name="TOP_5_S")

gene_names = expr_df.iloc[:, 0].astype(str)
expr_data = expr_df.iloc[:, 1:]

# classify samples: controls have 'UNC' in name
control_cols = [col for col in expr_data.columns if 'UNC' in col]
infected_cols = [col for col in expr_data.columns if 'UNC' not in col]

X_all = expr_data[control_cols + infected_cols].T
X_all.columns = gene_names
y = np.array([0]*len(control_cols) + [1]*len(infected_cols))  # 0 = control, 1 = infected
X=X_all.values

lr = LogisticRegression(max_iter=1000)
svm = SVC(kernel='linear',probability=True)  # probability needed for soft voting
rf = RandomForestClassifier(n_estimators=100, random_state=42)
xgb = XGBClassifier(n_estimators=100,max_depth=2,learning_rate=0.05,subsample=0.8,colsample_bytree=0.8,reg_alpha=0.1,reg_lambda=1,eval_metric='logloss',random_state=42)
# voting_clf = VotingClassifier(
#     estimators=[('lr', lr), ('svm', svm), ('rf', rf), ('xgb', xgb)],
#     voting='soft'
# )
# stacking_clf = StackingClassifier(
#     estimators=[('lr', lr), ('svm', svm), ('rf', rf)],
#     final_estimator=LogisticRegression(),
#     cv=5
# )
models = {
    'Logistic Regression': lr,
    'SVM': svm,
    'Random Forest': rf,
    'XGBoost': xgb,
    # 'Voting Ensemble': voting_clf,
    # 'Stacking Ensemble': stacking_clf
}

# cross
loo = LeaveOneOut()

gene_set_names = ["S_20","S_30","S_40","S_50","S_60","S_70","S_80","S_92"]
gene_set_files = "/content/drive/MyDrive/YASH-SCREENED_DATA.xlsx" # adjust to your files/sheets

all_results = []

for gene_set_name in (gene_set_names):
    # ... load X, y for this gene set ...
    expr_df = pd.read_excel("/content/drive/MyDrive/YASH-SCREENED_DATA.xlsx", sheet_name=gene_set_name)
    gene_names = expr_df.iloc[:, 0].astype(str)
    expr_data = expr_df.iloc[:, 1:]

    control_cols = [col for col in expr_data.columns if 'UNC' in col]
    infected_cols = [col for col in expr_data.columns if 'UNC' not in col]
    X_all = expr_data[control_cols + infected_cols].T
    X_all.columns = gene_names
    y = np.array([0]*len(control_cols) + [1]*len(infected_cols))
    X = X_all.values

    for model_name, model in models.items():
        # --- run LOOCV, collect metrics fold-by-fold ---
        fold_metrics = {m: [] for m in ["Accuracy","Precision","Recall","Specificity","F1","MCC"]}
        y_true_all, y_prob_all = [], []

        loo = LeaveOneOut()
        for train_idx, test_idx in loo.split(X):
            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            y_prob = model.predict_proba(X_test)[:, 1]

            # Per-fold metrics
            fold_metrics["Accuracy"].append(accuracy_score(y_test, y_pred))
            fold_metrics["Precision"].append(precision_score(y_test, y_pred, zero_division=0))
            fold_metrics["Recall"].append(recall_score(y_test, y_pred))
            fold_metrics["Specificity"].append(recall_score(y_test, y_pred, pos_label=0))
            fold_metrics["F1"].append(f1_score(y_test, y_pred))
            fold_metrics["MCC"].append(matthews_corrcoef(y_test, y_pred))

            y_true_all.append(y_test[0])
            y_prob_all.append(y_prob[0])

        # --- Summaries for this gene set + model ---
        summary_df = pd.DataFrame(fold_metrics).agg(['mean','std']).T
        summary_df.columns = ['Mean', 'StdDev']
        summary_df['Mean±SD'] = summary_df['Mean'].round(3).astype(str) + " ± " + summary_df['StdDev'].round(3).astype(str)

        # --- AUC (pooled + bootstrap std) ---
        auc_mean = roc_auc_score(y_true_all, y_prob_all)
        auc_scores = []
        for _ in range(500):  # bootstrap
            idxs = np.random.choice(len(y_true_all), len(y_true_all), replace=True)
            if len(np.unique(np.array(y_true_all)[idxs])) < 2:
                continue
            auc_scores.append(roc_auc_score(np.array(y_true_all)[idxs],
                                            np.array(y_prob_all)[idxs]))
        auc_std = np.std(auc_scores)
        summary_df.loc["AUC"] = [auc_mean, auc_std, f"{auc_mean:.3f} ± {auc_std:.3f}"]

        # --- Store results for each metric ---
        for metric, row in summary_df.iterrows():
            all_results.append({
                "GeneSet": gene_set_name,
                "Model": model_name,
                "Metric": metric,
                "Mean": row['Mean'],
                "StdDev": row['StdDev'],
                "Mean±SD": row['Mean±SD']
            })

# --- Convert all results into DataFrame ---
all_results_df = pd.DataFrame(all_results)
all_results_df.to_csv("/content/drive/MyDrive/std/1s_gene_sets_mean_sd.csv", index=False)

# --- Now compute average stddev across gene sets ---
avg_std_df = all_results_df.groupby(["Model","Metric"])["StdDev"].mean().reset_index()
avg_std_df.to_csv("/content/drive/MyDrive/std/1saverage_stddev_across_gene_sets.csv", index=False)

import numpy as np
import pandas as pd
from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, matthews_corrcoef
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier
from joblib import Parallel, delayed

# -----------------------------
# Models
# -----------------------------
models = {
    "RandomForest": RandomForestClassifier(random_state=42),
    "LogisticRegression": LogisticRegression(max_iter=1000, random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42)
}

# -----------------------------
# Evaluation functions
# -----------------------------
def evaluate_model(X, y, model, loo):
    y_true_all, y_pred_all, y_prob_all = [], [], []

    for train_idx, test_idx in loo.split(X):
        model.fit(X[train_idx], y[train_idx])
        y_pred = model.predict(X[test_idx])
        y_prob = model.predict_proba(X[test_idx])[:, 1]
        y_true_all.append(y[test_idx][0])
        y_pred_all.append(y_pred[0])
        y_prob_all.append(y_prob[0])

    metrics = {}
    metrics["Accuracy"] = accuracy_score(y_true_all, y_pred_all)
    metrics["Precision"] = precision_score(y_true_all, y_pred_all, zero_division=0)
    metrics["Recall"] = recall_score(y_true_all, y_pred_all)
    metrics["F1"] = f1_score(y_true_all, y_pred_all)
    metrics["MCC"] = matthews_corrcoef(y_true_all, y_pred_all)
    metrics["AUC"] = roc_auc_score(y_true_all, y_prob_all)

    return metrics


def single_permutation(X, y, model, loo):
    y_perm = np.random.permutation(y)
    try:
        return evaluate_model(X, y_perm, model, loo)
    except Exception:
        return None


def permutation_test_parallel_all(X, y, model, n_permutations=200, n_jobs=-1):
    loo = LeaveOneOut()

    # --- observed performance ---
    observed = evaluate_model(X, y, model, loo)

    # --- run permutations in parallel ---
    perm_results = Parallel(n_jobs=n_jobs, verbose=0)(
        delayed(single_permutation)(X, y, model, loo) for _ in range(n_permutations)
    )
    perm_results = [res for res in perm_results if res is not None]

    # --- aggregate null distributions ---
    perm_metrics = {m: [res[m] for res in perm_results if not np.isnan(res[m])] for m in observed.keys()}

    # --- p-values ---
    pvals = {}
    perm_means = {}
    for metric, obs_val in observed.items():
        null_scores = np.array(perm_metrics[metric])
        perm_means[metric] = np.mean(null_scores)
        pvals[metric] = (np.sum(null_scores >= obs_val) + 1) / (len(null_scores) + 1)

    return observed, perm_means, pvals

# -----------------------------
# Run for all gene sets + models
# -----------------------------
def run_permutation_pipeline(expr_file, gene_sets, n_permutations=200, n_jobs=-1, out_csv="/content/drive/MyDrive/Sensepermutation_results_as.csv"):
    results = []

    for gene_set_name in gene_sets:
        # Load data
        expr_df = pd.read_excel(expr_file, sheet_name=gene_set_name)
        gene_names = expr_df.iloc[:, 0].astype(str)
        expr_data = expr_df.iloc[:, 1:]

        control_cols = [col for col in expr_data.columns if "UNC" in col]
        infected_cols = [col for col in expr_data.columns if "UNC" not in col]

        X_all = expr_data[control_cols + infected_cols].T
        X_all.columns = gene_names
        y = np.array([0] * len(control_cols) + [1] * len(infected_cols))
        X = X_all.values

        # Run models
        for model_name, model in models.items():
            observed, perm_means, pvals = permutation_test_parallel_all(
                X, y, model, n_permutations=n_permutations, n_jobs=n_jobs
            )

            for metric in observed.keys():
                results.append({
                    "GeneSet": gene_set_name,
                    "Model": model_name,
                    "Metric": metric,
                    "Observed": round(observed[metric], 3),
                    "NullMean": round(perm_means[metric], 3),
                    "p-value": round(pvals[metric], 4)
                })

    results_df = pd.DataFrame(results)
    results_df.to_csv(out_csv, index=False)
    return results_df

gene_sets = ["S_20","S_30","S_40","S_50","S_60","S_70","S_80","S_92"]
expr_file = "/content/drive/MyDrive/YASH-SCREENED_DATA.xlsx"
results_df = run_permutation_pipeline(expr_file, gene_sets, n_permutations=200, n_jobs=-1)
print(results_df)